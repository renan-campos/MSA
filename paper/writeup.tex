
\documentclass[11pt,letterpaper]{article}
\usepackage{naaclhlt2013}
\usepackage{times}
\usepackage{multirow}
\usepackage{caption}
\usepackage{latexsym}
\usepackage{graphicx}
\graphicspath{{images/}}
\setlength\titlebox{6.5cm}

\title{MSA: Movie Sentiment Analysis}
%\author[1]{Renan Campos\thanks{Renan\_Campos@student.uml.edu}}
%\author[1]{Connor Cooper\thanks{Connor\_Cooper@student.uml.edu}}
%\author[1]{Kevin Wacome\thanks{Kevin\_Wacome@student.uml.edu}}
%\affil[1]{Department of Computer Science, University of Massachusetts Lowell}

\begin{document}
\maketitle
\begin{abstract}
This paper describes the system we implemented for the machine learning course project. We participated in the sentiment analysis competition task. This system avoids the usage of hand-crafted features to generate word vector representations that encode semantic and sentiment information by following the approaches of Mass, et al (2011). We were able to generate a categorization accuracy of $87.5\%$, according to kaggle metrics. This accuracy is very close to the second and third place systems and the best performing system achieved an accuracy of $89.1\%$.


\end{abstract}

\section{Introduction}

When someone is shopping for an appliance, or trying to pick a movie to watch, they will often look at the reviews of that particular product. These reviews express sentiment - thoughts influenced by or proceeding from feeling or emotion. Because people consider the sentiment of others when making decisions, sentiment analysis is a well-motivated area of research.

In this paper, we present our solution to a key sentiment analysis task: being able to identify whether a movie review is positive or negative. This is a well-researched task, with many proposed solutions, as we will show in our background section. Our model allows for non-handcrafted feature sets and requires little prior knowledge. We will describe each component of our system and provide an overview of our learning model. After presenting the system in detail, we will describe the data set and experiments that were run. We’ll conclude with our evaluation on how successful our model as and our main takeaways.
Put Introduction Here.


\section{Relevant Literature and Related Works}

Various approaches to sentiment analysis have been explored over the years. Pang, et. al, (2002) attempts the task of sentiment analysis using models known to do well in topic-classification, and explore why sentiment analysis is more difficult. The models tried include naive bayes, maximum entropy and support vector machine, and use a couple of different feature sets involving unigrams, bigrams, adjectives, part of speech, and position of words. Their data does show that these models don’t perform as well on sentiment analysis as they would in topic-classification. They believe that this disparity is due to “thwarted expectations”, where a reviewer will describe good attributes that they expected, only to point out that these expectations were not satisfied by the movie. In order to achieve better results, the challenge of identifying  thwarted expectations will need to be addressed. The authors suggest identifying features that indicate whether the current sentence is on-topic. This likely means to distinguish when the actual movie is being talked about, and when expectations are the subject. This paper also effectively articulates a way to handle the negation of phrases (“good” vs. “not good”) originally described by Das and Mike (2001). Pang, et al. (2002) suggests adding NOT\_ to all the words between the negation word and the next punctuation.   

Another approach introduced by Mass, et al, (2011) utilizes different supervised and unsupervised methods to capture semantic information in a vectorized representation. They present a model to capture both semantic and sentiment similarities among words. This model learns semantic vectors that encode sentiment information. The author’s semantic component learns word vectors via an unsupervised probabilistic model of documents. The supervised  sentiment component of the model uses the vector representation of words to predict the sentiment annotations on contexts in which the words appear. This causes words expressing  similar sentiment to have similar vector representation. These vector representations are then used as features for an SVM to classify polarity of movie reviews. The authors were able to obtain an high accuracy of 88.89\% on a movie review task similar to the one this paper attempts to solve.

\section{Data and Tools}

Put Data + Tools

\section{System}

Our implementation employs the learning algorithms described in Mass, et al (2011). Figure 1 provides a diagram of our system’s architecture. Our system was written in Python, with each component coded as a module.


Figure 1. MSA’s System Architecture.

\subsection{Preprocessing}

Before working on tokenizing and vectorizing the data, we introduced a layer of abstraction to make the data easier to work with. The training and test sets are treated as sets of Reviews, which is a class containing helper functions that efficiently retrieve information from a review, such as the raw text or its i.d., without keeping all of it in memory. This abstraction makes the main script easier to code because the names of the objects and methods are intuitive.

Tokenizing is important because it is what takes the text from the reviews and breaks it up into significant chunks for processing. Issues that were tackled for this part of the project included determining how to tokenize the text, and deciding what to keep/discard. We based our tokenizer off of a tutorial that was specific to tokenizing sentiment in twitter tweets (http://sentiment.christopherpotts.net/tokenizing.html). We only addressed a subset of the concepts that the tutorial covers as some weren't relevant to movie reviews. The tokenizer that we built is able to capture emoticons such as :) and >:[. We felt this was important as these are occasionally used in informal writing to express emotion. Punctuation was also kept as a token, as certain occurrences of punctuation (such as ! or ...) can also contribute to the semantics of the sentence. Capitalization was taken out, and all letters, with the exception of those in emoticons, were lowercased, as we felt this distinction would lead to unnecessary sparseness when vectorizing later on.

To decide how much to keep from the text, we followed the original paper's logic, and created a function that will fix the vocabulary to the N most frequent words, ignoring the first M words as a sort of stop word removal mechanism. The original paper specifically used 5,000 words, ignoring the first 50. We will also use this configuration initially when testing the baseline. Ideally, more words tokenized would be better, but it may be computationally impractical to tokenize all of the words, as the dataset has over 80,000 vocabulary words.

After tokenizing the text, vectorizing is the next logical step, as the algorithms we plan on using require the data to be in this representation. We use the scikit module to help build both tf-idf weighted bag of words vectors for each Review, and one-hot vectors for each word in the Review, as these are the representations that we currently need.

The tokenizing and vectorizing step are actually done at the same time, so the vectorizer needs to parse through all of the training data in order to determine the N most frequent words that it will use in its vocabulary. This takes about 3 minutes to complete, so to save time, the trained vectorizers are serialized to a file so that they can be reused. Reloading these files take no longer than half a second, so this is a real time-saver.


\subsection{Semantic Features}

\subsection{Sentiment Features}

\begin{thebibliography}{}

%% example citations
\bibitem[\protect\citename{Ling, Weld}2010]{Ling:25}
Xiao Ling and Daniel S. Weld.
\newblock 2010.
\newblock {\em  Temporal Information Extraction}.

%\bibitem[\protect\citename{Llorens \bgroup et al.\egroup}2015]{Llorens:15}
%Hector Llorens, Nate Chambers, Naushad UzZaman, Nasrin %Mostafazadeh, James Allen and James Pustejovsky.
%\newblock 2015.
%\newblock {\em TempEval: Evaluating Temporal %Information Understanding with QA}.

%\bibitem[\protect\citename{{Llorens \bgroup et al.\egroup}}2015]{Llorens:16}
%Hector Llorens, Nathanael Chambers, Naushad UzZaman, Nasrin Mostafazadeh, James Allen and James Pustejovsky.
%\newblock 2015.
%\newblock {\em SemEval-2015 Task 5: QA TEMPEVAL-Evaluating Temporal Information Understanding with Question Answering}.

%\bibitem[\protect\citename{{Mirza, Minard}}2015]{Mirza:15}
%Paramita Mirza and Anne-Lyse Minard.
%\newblock 2015.
%\newblock {\em HLT-FBK: a Complete Temporal Processing System for QA TempEval}.

\end{thebibliography}
\end{document}
